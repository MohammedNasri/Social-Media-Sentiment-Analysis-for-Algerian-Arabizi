{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXR3xZYy_cz3"
      },
      "source": [
        "# Configuration and module installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06anf03A_cz7"
      },
      "outputs": [],
      "source": [
        "pip install google-api-python-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwHP3BQQ_cz_"
      },
      "outputs": [],
      "source": [
        "pip install google-auth google-auth-oauthlib google-auth-httplib2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYo6fR4W_c0B"
      },
      "source": [
        "# The real business starts HERE !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8vri7pR_c0C"
      },
      "outputs": [],
      "source": [
        "CLIENT_SECRETS_FILE = \"client_secret3.json\"\n",
        "SCOPES = ['https://www.googleapis.com/auth/youtube.force-ssl']\n",
        "API_SERVICE_NAME = 'youtube'\n",
        "API_VERSION = 'v3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmTQ342-_c0D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import google.oauth2.credentials\n",
        " \n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from google.auth.transport.requests import Request\n",
        " \n",
        "...\n",
        "...\n",
        " \n",
        "def get_authenticated_service():\n",
        "    credentials = None\n",
        "    if os.path.exists('token.pickle'):\n",
        "        with open('token.pickle', 'rb') as token:\n",
        "            credentials = pickle.load(token)\n",
        "    #  Check if the credentials are invalid or do not exist\n",
        "    if not credentials or not credentials.valid:\n",
        "        # Check if the credentials have expired\n",
        "        if credentials and credentials.expired and credentials.refresh_token:\n",
        "            credentials.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                CLIENT_SECRETS_FILE, SCOPES)\n",
        "            credentials = flow.run_console()\n",
        " \n",
        "        # Save the credentials for the next run\n",
        "        with open('token.pickle', 'wb') as token:\n",
        "            pickle.dump(credentials, token)\n",
        " \n",
        "    return build(API_SERVICE_NAME, API_VERSION, credentials = credentials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6y62dCn_c0G"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # When running locally, disable OAuthlib's HTTPs verification. When\n",
        "    # running in production *do not* leave this option enabled.\n",
        "    os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
        "    service = get_authenticated_service()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gzSG61e_c0I"
      },
      "outputs": [],
      "source": [
        "def get_videos(service, **kwargs):\n",
        "    final_results = []\n",
        "    results = service.search().list(**kwargs).execute()\n",
        "\n",
        "\n",
        "    \n",
        "      \n",
        "    i = 0\n",
        "    max_pages = 5\n",
        "    while results and i < max_pages:\n",
        "        final_results.extend(results['items'])\n",
        "\n",
        "        # Check if another page exists\n",
        "        if 'nextPageToken' in results:\n",
        "            kwargs['pageToken'] = results['nextPageToken']\n",
        "            results = service.search().list(**kwargs).execute()\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return final_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTZqejS2_c0L"
      },
      "outputs": [],
      "source": [
        "def get_video_comments(service, **kwargs):\n",
        "    comments = []\n",
        "    results = service.commentThreads().list(**kwargs).execute()\n",
        "    \n",
        "    while results:\n",
        "        for item in results['items']:\n",
        "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "            comments.append(comment)\n",
        " \n",
        "        if 'nextPageToken' in results:\n",
        "            kwargs['pageToken'] = results['nextPageToken']\n",
        "            results = service.commentThreads().list(**kwargs).execute()\n",
        "        else:\n",
        "            break\n",
        " \n",
        "    return comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueYxpyRU_c0O"
      },
      "outputs": [],
      "source": [
        "def search_videos_by_keyword(service, **kwargs):\n",
        "    results = get_videos(service, **kwargs)\n",
        "    \n",
        "    list_comms = []\n",
        "    for item in results:\n",
        "        title = item['snippet']['title']\n",
        "        video_id = item['id']['videoId']\n",
        "\n",
        "        try:\n",
        "            comments = get_video_comments(service, part='snippet', videoId=video_id, textFormat='plainText')\n",
        "            for comment in comments:\n",
        "                list_comms.append(comment)\n",
        "        except:\n",
        "            print('disabled comments')\n",
        "        \n",
        "        \n",
        "    return list_comms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk4l7x_G_c0Q"
      },
      "outputs": [],
      "source": [
        "def isEnglish(s):\n",
        "    if s.isascii():\n",
        "        return s\n",
        "    else:\n",
        "        return \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m81-M6AL_c0R"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "def write_to_csv(comments):\n",
        "    df = pd.Series(comments)\n",
        "    df = df.apply(lambda x:isEnglish(x))\n",
        "    df = df[df!='false']\n",
        "    df.to_csv('out.csv', index=False, header=False)  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Z16wOyF6_c0S",
        "outputId": "66058405-24d3-4f0e-cc34-2a2c93cbab22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a keyword: algerie\n"
          ]
        }
      ],
      "source": [
        "keyword = input('Enter a keyword: ')\n",
        "comments = search_videos_by_keyword(service, q=keyword, part='id,snippet', eventType='completed', type='video')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMDZJO5f_c0T"
      },
      "outputs": [],
      "source": [
        "write_to_csv(comments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmVXfWRY_c0U"
      },
      "source": [
        "## Assembling all the outputs in one dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZZEI_UK_c0U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "all_csv = []\n",
        "for i in range(1,5):\n",
        "    all_csv.append('out'+str(i)+'.csv')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oh0q5dvm_c0W"
      },
      "outputs": [],
      "source": [
        "li = []\n",
        "\n",
        "for filename in all_csv:\n",
        "    df = pd.read_csv(filename, index_col=None, header=None,error_bad_lines=False)\n",
        "    li.append(df)\n",
        "\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1Bxag0X_c0X"
      },
      "outputs": [],
      "source": [
        "write_to_csv(frame[0].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p78NDGYn_c0Y"
      },
      "source": [
        "# Joining the current dataset with the new one and removing duplicated values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDTKhfJJ_c0Y"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(\"dataset.csv\",header=None)\n",
        "df2 = pd.read_csv(\"out.csv\",header=None)\n",
        "\n",
        "li = []\n",
        "\n",
        "li.append(df1)\n",
        "li.append(df2)\n",
        "\n",
        "df = pd.concat(li, axis=0, ignore_index=True)\n",
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FCiHR9u_c0Y"
      },
      "outputs": [],
      "source": [
        "df.to_csv('dataset.csv', index=False, header=False)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltZd-mEU_c0Z"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXPpu5eF_c0Z"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WBy6vcT_c0Z"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3b4zsMw_c0a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s80w8pj_c0a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNkxYgH7_c0b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfTv7EtX_c0b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Web scrapping with YouTube API.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}